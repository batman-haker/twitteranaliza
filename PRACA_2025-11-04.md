# Twitter Analyzer - Praca z dnia 2025-11-04

## Podsumowanie

Dzisiaj naprawiliśmy paginację i stworzyliśmy system do masowego pobierania tweetów z wielu kont jednocześnie.

---

## 1. Naprawa Paginacji (50-100 tweetów)

### Problem
- Slider w aplikacji pozwalał wybrać 5-100 tweetów
- API zawsze zwracało tylko 20 tweetów, niezależnie od ustawienia
- Paginacja nie działała

### Rozwiązanie
**Główny problem:** Cursor do paginacji był w złym miejscu w strukturze odpowiedzi API.

**Błędny kod (twitter_client.py:124):**
```python
cursor = tweets_data.get('cursor')  # Szukał w data.cursor
```

**Poprawiony kod (twitter_client.py:120-122):**
```python
# Cursor jest na poziomie root, nie w data!
has_next_page = data.get('has_next_page', False)
cursor = data.get('next_cursor') if has_next_page else None
```

**Struktura odpowiedzi TwitterAPI.io:**
```json
{
  "status": "success",
  "has_next_page": true,
  "next_cursor": "DAADDAABCgABG440...",
  "data": {
    "tweets": [...]
  }
}
```

### Rezultat
✅ Aplikacja teraz pobiera 5-100 tweetów zgodnie z ustawieniem slidera
✅ Paginacja działa poprawnie
✅ Test: Pomyślnie pobrano 100 tweetów w 5 requestach (20 tweetów × 5)

---

## 2. Skrypt Batch Fetch

### Cel
Pobieranie 50 tweetów z wielu kont jednocześnie i zapisanie każdego konta do osobnego pliku JSON.

### Plik: `twitter-analyzer/backend/batch_fetch.py`

### Funkcjonalności
- Pobiera tweety z listy kont (jeden po drugim)
- Zapisuje każde konto do osobnego JSON w folderze `exports/batch/`
- Format pliku: `{username}_{timestamp}.json`
- Pokazuje postęp i statystyki
- Obsługuje błędy (user not found, rate limits)

### Użycie
```bash
cd twitter-analyzer/backend
py -u batch_fetch.py
```

### Konfiguracja w skrypcie
```python
# Edytuj listę kont w batch_fetch.py:
accounts = [
    "stocktavia",
    "wallstengine",
    # ... więcej kont
]

MAX_TWEETS = 50  # Liczba tweetów na konto
ANALYZE_LINKS = False  # Czy analizować linki (Claude AI)
```

---

## 3. Masowe Pobranie - Wykonanie

### Lista kont (33 konta)

**Giełda (16):**
- stocktavia, PelosiTracker_, wallstengine, ksochanek, Dan_Kostecki
- HayekAndKeynes, Inwestomat_eu, hedgefundowiec, rditrych
- Maciej__Czajka, PiotrZolkiewicz, PawelMalik_GG, AnalitykF
- conksresearch, sentimentrader, Joker68069137

**Kryptowaluty (5):**
- KO_Kryptowaluty, Dystopia_PL, Dziewczynka_z_, wesleyplpl, Paul__Crow

**Gospodarka (3):**
- wstepien_, KamSobolewski, T_Smolarek

**Polityka (2):**
- realDonaldTrump, MikolajVonskyT

**AI (4):**
- popai_pl, huggingface, rpl_0x, miroburn

**Filozofia (3):**
- orangebook_, naval, andrzejdragan

### Wyniki

**✅ Pomyślnie: 29 kont**
- Wszystkie pliki JSON zapisane w `exports/batch/`
- Format: `username_20251104_HHMMSS.json`

**❌ Błędy: 4 konta**
1. **PelosiTracker_** - user not found (konto nie istnieje)
2. **Dziewczynka_z_** - błąd kodowania emoji (plik zapisany!)
3. **Paul__Crow** - błąd kodowania emoji (plik zapisany!)
4. **orangebook_** - błąd kodowania emoji (plik zapisany!)

**Uwaga:** 3 konta z błędem emoji MAJĄ zapisane pliki JSON! Błąd był tylko przy wyświetlaniu statystyk.

### Statystyki
- **Czas wykonania:** ~7 minut
- **Łącznie tweetów:** ~1,600 (32 konta × 50 tweetów)
- **Pliki zapisane:** 32 pliki JSON
- **Rozmiar danych:** ~161 KB na konto (średnio)

---

## 4. Struktura Plików

### Lokalizacja
```
C:\Xscrap\twitter-analyzer\
├── backend\
│   ├── twitter_client.py      # Naprawiona paginacja
│   ├── batch_fetch.py          # Nowy skrypt masowy
│   ├── main.py                 # FastAPI backend
│   └── link_analyzer.py
├── frontend\
│   └── app\
│       └── page.tsx            # UI z sliderem
└── exports\
    └── batch\                  # TUTAJ SĄ PLIKI JSON
        ├── stocktavia_20251104_082014.json
        ├── wallstengine_20251104_082018.json
        ├── Dan_Kostecki_20251104_082023.json
        └── ... (32 pliki)
```

### Zawartość JSON
Każdy plik zawiera:
```json
{
  "success": true,
  "username": "stocktavia",
  "user_info": {
    "id": "...",
    "name": "Stocktavian August",
    "userName": "stocktavia",
    "followersCount": 123456,
    "followingCount": 789
  },
  "total_tweets": 50,
  "tweets": [
    {
      "id": "1234567890",
      "text": "Tweet content...",
      "created_at": "2025-11-04T...",
      "tweet_url": "https://twitter.com/stocktavia/status/1234567890",
      "is_thread": true,
      "metrics": {
        "like_count": 100,
        "retweet_count": 20,
        "reply_count": 5,
        "view_count": 5000
      },
      "extracted_links": ["https://example.com/article"]
    }
  ],
  "fetched_at": "2025-11-04T08:20:14"
}
```

---

## 5. Uruchomienie Aplikacji

### Backend (FastAPI)
```bash
cd twitter-analyzer/backend
py -m uvicorn main:app --reload --port 8000
```
Dostępny na: http://localhost:8000

### Frontend (Next.js)
```bash
cd twitter-analyzer/frontend
npm run dev
```
Dostępny na: http://localhost:3000

### Web Interface
- Otwórz http://localhost:3000
- Wpisz username (np. "elonmusk")
- Ustaw slider (5-100 tweetów)
- Zaznacz opcje:
  - ☑ Analizuj linki (Claude AI) - wolniejsze
  - ☑ Zapisz do JSON
- Kliknij "Analizuj profil"

---

## 6. Konfiguracja

### Wymagane API Keys w `.env`:
```env
# TwitterAPI.io
TWITTERAPI_IO_KEY=your_key_here

# Claude AI (opcjonalne, do analizy linków)
CLAUDE_API_KEY=your_key_here
```

### Lokalizacja .env
```
C:\Xscrap\twitter-analyzer\.env
```

---

## 7. Kolejne Kroki / TODO

### Możliwe ulepszenia:
1. **Napraw emoji w print()** - dodaj encoding='utf-8' do stdout
2. **Rate limiting** - dodaj opóźnienia między requestami jeśli API limituje
3. **Resume capability** - możliwość wznowienia przerwanych pobierań
4. **Progress bar** - lepsze UI dla postępu
5. **Export do CSV** - oprócz JSON
6. **Filtrowanie tweetów** - po dacie, metrykach, itp.
7. **Analiza AI całego profilu** - podsumowanie wszystkich tweetów

### Znane problemy:
- Emoji w Windows console powodują UnicodeEncodeError (nie wpływa na JSON)
- API nie zwraca liczby followerów (pokazuje 0) - problem po stronie TwitterAPI.io
- Niektóre konta mogą mieć <50 tweetów (normalne)

---

## 8. Komendy szybkiego dostępu

### Pobierz tweety z 1 konta (web UI)
1. Uruchom backend: `cd twitter-analyzer/backend && py -m uvicorn main:app --reload --port 8000`
2. Uruchom frontend: `cd twitter-analyzer/frontend && npm run dev`
3. Otwórz: http://localhost:3000

### Pobierz tweety z wielu kont (batch)
```bash
cd twitter-analyzer/backend
py -u batch_fetch.py
```

### Zobacz pobrane pliki
```bash
dir twitter-analyzer\exports\batch\*.json
```

### Przeczytaj JSON w Python
```python
import json

with open('exports/batch/stocktavia_20251104_082014.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

print(f"User: {data['user_info']['name']}")
print(f"Total tweets: {data['total_tweets']}")
for tweet in data['tweets'][:3]:
    print(f"- {tweet['text'][:100]}...")
```

---

## 9. Dokumentacja techniczna

### twitter_client.py - Główne funkcje

#### `get_user_tweets(username, max_results=50)`
Pobiera tweety użytkownika z paginacją.

**Parametry:**
- `username` (str): Username bez @
- `max_results` (int): 5-100, ile tweetów pobrać

**Zwraca:**
```python
{
    "success": bool,
    "username": str,
    "user_info": dict,
    "total_tweets": int,
    "tweets": list
}
```

**Mechanizm paginacji:**
- API zwraca max 20 tweetów per request
- Używa `has_next_page` i `next_cursor` z root levelu
- Loop do max_results / 20 requestów

### batch_fetch.py - Główne funkcje

#### `fetch_and_save_account(username, max_tweets=50, analyze_links=True)`
Pobiera i zapisuje tweety jednego konta.

#### `batch_fetch_accounts(accounts, max_tweets=50, analyze_links=True)`
Przetwarzanie listy kont.

---

## 10. Linki i zasoby

### API Documentation
- TwitterAPI.io: https://docs.twitterapi.io/
- Anthropic Claude: https://docs.anthropic.com/

### Projekt
- Backend: FastAPI + TwitterAPI.io
- Frontend: Next.js + TypeScript + Tailwind CSS
- AI: Claude 3.5 (do analizy linków)

### Lokalizacja projektu
```
C:\Xscrap\twitter-analyzer\
```

---

**Data utworzenia:** 2025-11-04
**Czas trwania pracy:** ~2 godziny
**Główne osiągnięcia:** Naprawa paginacji + batch fetch 33 kont
**Rezultat:** 32 pliki JSON z ~1,600 tweetami
